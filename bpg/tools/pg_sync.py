"""SyncDB comparison

Django's syncdb doesn't really 'syncronize' the database. We manually
change our postgres instance all of the time. This scripts helps us find
how different our database is from the database that Django creates.

One needs to create a new Django database by altering the DATABASE_NAME
in the Django settings file and then doing a syncdb. You will now have
two databases -- the current roduction database and a second database
that you just created (although empty). The compare_dbs script can be
used to see how different table rows and table columns are from what
Django would create.

Sample usage:
                
compare_dbs(DB(db_name='pfacts003_sandbox2',
               user_name='your_username',
               password='your_password',
               host='db'),
            DB(db_name='pfacts003_sandbox',
               user_name='your_username',
               password='your_password',
               host='db'))

Compare tables that are generated by Django and the tables that we have
in our database.

"""

import psycopg2
from itertools import repeat
import pprint
from copy import deepcopy


class DB(object):
    def __init__(self, db_name, user_name, password,
                 host='localhost', port=5432):
        self.connection = None
        self.db_name = db_name
        self.user_name = user_name
        self.password = password
        self.host = host
        self.port = port
        self.data = {}
        self._connect()

        print "Gathering data from '%s'..." % db_name
        self.get_tables()

    def _connect(self):
        connect_string = ("dbname=%s "\
                          "user=%s "\
                          "password=%s "\
                          "host=%s ") % (self.db_name, self.user_name,
                                         self.password, self.host)
        del self.password
        self.connection = psycopg2.connect(connect_string);

    def _execute(self, query_string):
        c = self.connection.cursor()
        c.execute(query_string)
        records = c.fetchall()

        return records

    def get_tables(self):
        if len(self.data.keys()) == 0:

            def default_column():
                default = {'cached_columns': False,
                           'cached_indexes': False,
                           'columns': (),
                           'column_data': {},
                           'indexes': []}
                while True:
                    yield deepcopy(default)
            generate_default = default_column()

            query_string = 'SELECT tablename FROM pg_tables'
            tables = self._execute(query_string)

            # Create a dictionary with keys of tablenames and default dict
            self.data =  dict(zip([t[0] for t in tables], generate_default))

        return sorted(self.data.keys())

    def get_columns(self, table):
        """Return column name and column type"""

        if table not in self.data.keys():
            return None

        if not self.data[table]['cached_columns']:
            # Column order is important for other code logic
            query_string =\
            """SELECT column_name, ordinal_position, data_type ,
                      character_maximum_length, is_nullable 
               FROM information_schema.columns
               WHERE table_name like '%s'
                   AND table_catalog='%s';
            """ % (table, self.db_name)

            # Create a dictionary of column names with value of tupe(ordinal_position, type)
            column_data = dict([(c[0], c[1:]) for c in self._execute(query_string)])

            # Walk columns and adjust strings for any 'character' or 'varying character'
            for c in column_data.keys():
                if column_data[c][2]:
                    # Build new record from original slices with modification
                    new_record = list(column_data[c][0:1])
                    new_record.append("%s(%s)" % column_data[c][1:3])
                    new_record.extend(column_data[c][2:])
                    column_data[c] = new_record

            self.data[table]['column_data'] = column_data
            self.data[table]['cached_columns'] = True

            # Add lengths to character and varying character

            # Create a dictionary of column fields where key is ordinal_position (for ordering)
            columns = dict([(column_data[c][0], c) for c in column_data.keys()])

            self.data[table]['columns'] = \
                [columns[c] for c in sorted(columns.keys())]


        return self.data[table]['columns']

    def get_column_type(self, table, column):
        # We may as well grab all data related to the column instead of
        # hitting the database several times.
        if not self.data[table]['cached_columns']:
            self.get_columns(table)

        # Look up from pre-fetched column structure
        return self.data[table]['column_data'][column][1]

    def get_indexes(self, table):
        pass

    def get_primary_keys(self, table):
        query_string =\
        """
        select  
            tc.constraint_name,
            col.column_name
        from
            information_schema.table_constraints tc,
            information_schema.constraint_column_usage col
        where tc.table_name = '%s'
        and tc.constraint_name = col.constraint_name
        and tc.constraint_type = 'PRIMARY KEY';
        """ % table

    def get_foreign_keys(self, table):
        query_string =\
        """
        select  
            tc.constraint_name,
            'unknown' as column_name,
            tab.table_name,
            col.column_name,
            tc.is_deferrable,
            tc.initially_deferred,
            rc.unique_constraint_name
        from
            information_schema.table_constraints tc,
            information_schema.constraint_column_usage col,
            information_schema.constraint_table_usage tab,
            information_schema.referential_constraints rc
        where tc.table_name = 'uniprot_go'
        and tc.constraint_name = col.constraint_name
        and tc.constraint_name = tab.constraint_name
        and tc.constraint_name = rc.constraint_name
        and tc.constraint_type = 'FOREIGN KEY';
        """ % table

    def get_unique_constraints(self, table):
        query_string =\
        """
        SELECT tc.constraint_name, col.column_name
        FROM 
            information_schema.table_constraints tc,
            information_schema.constraint_column_usage col
        WHERE constraint_type='UNIQUE'
        and tc.table_name = 'uniprot'
        and tc.constraint_name = col.constraint_name;
        """ % table


def compare_dbs(db1, db2):
    db1_tables_set = set(db1.get_tables())
    db2_tables_set = set(db2.get_tables())
    master_table_list = db1_tables_set.intersection(db2_tables_set)

    print "Pass 1: Checking Tables"
    errors = False
    for table in db1_tables_set - db2_tables_set:
        errors = True
        print "\tAlert: Table %s is missing from first database." % table

    for table in db2_tables_set - db1_tables_set:
        errors = True
        print "\tAlert: Table %s is missing from second database." % table

    if not errors: 
        print "\tNo errors found"

    print "Pass 2: Checking Columns"
    for table in master_table_list:
        db1_columns_set = set(db1.get_columns(table))
        db2_columns_set = set(db2.get_columns(table))
        for column in db1_columns_set - db2_columns_set:
            print ("\tAlert: Database: %s table: '%s' column: %s "
                   "missing from %s/%s" % (db1.db_name, table, column,
                                           db2.db_name, table))

        for column in db2_columns_set - db1_columns_set:
            print ("\tAlert: Database: %s table: '%s' column: %s "
                   "missing from %s/%s" % (db2.db_name, table, column,
                                           db1.db_name, table))
    print "Pass 3: Checking Column Types"
    for table in master_table_list:
        common_columns = set(db1.get_columns(table)).\
            intersection(set(db2.get_columns(table)))
        for column in common_columns:
            if db1.get_column_type(table, column) != \
               db2.get_column_type(table, column):
                print ("\tAlert: Column type mismatch for table '%s' "
                       "and column '%s'. DB: '%s' type '%s' "
                       "DB: '%s' type '%s'" % (table, column,
                           db1.db_name, db1.get_column_type(table, column),
                           db2.db_name, db2.get_column_type(table, column)))

                
compare_dbs(DB(db_name='pfacts003_sandbox2',
               user_name='<snip>',
               password='<snip>',
               host='db'),
            DB(db_name='pfacts003_sandbox',
               user_name='<snip>',
               password='<snip>',
               host='db'))

#x=DB(db_name='pfacts003_sandbox2',
#     user_name='<snip>',
#     password='<snipped>',
#     host='db')
#print x.get_tables()
#for table in x.get_tables():
#    print x.get_columns(table)
#pprint.pprint(x.data)
